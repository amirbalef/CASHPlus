{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update(\n",
    "    {\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times\"],\n",
    "        \"axes.labelsize\": 14,  # Match your ECAI paper font size\n",
    "        \"font.size\": 14,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Complex\"\n",
    "\n",
    "dataset = pd.read_csv(\"../Datasets/\" + dataset_name + \".csv\")\n",
    "\n",
    "instances = sorted(dataset[\"instance\"].unique())\n",
    "print(instances)\n",
    "all_arm_index_list = dataset[\"arm_index\"].unique()\n",
    "valid_arm_index_list = [item for item in all_arm_index_list if item >= 0]\n",
    "number_of_arms = len(valid_arm_index_list)\n",
    "number_of_trails = len(dataset[\"repetition\"].unique())\n",
    "max_horizon_time = len(dataset[\"iteration\"].unique())\n",
    "combined_search_algorithms = dataset[dataset[\"arm_index\"] < 0][\"optimizer\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "for instance in instances:\n",
    "    print(instance)\n",
    "    df = dataset[(dataset[\"instance\"] == instance)][\n",
    "        [\n",
    "            \"instance\",\n",
    "            \"arm_name\",\n",
    "            \"arm_index\",\n",
    "            \"repetition\",\n",
    "            \"iteration\",\n",
    "            \"loss\",\n",
    "            \"eval_time\",\n",
    "        ]\n",
    "    ]\n",
    "    filtered_df = df\n",
    "\n",
    "    filtered_df[\"incumbent_loss\"] = (\n",
    "        filtered_df.sort_values([\"instance\", \"arm_index\", \"repetition\", \"iteration\"])\n",
    "        .groupby([\"instance\", \"arm_index\", \"repetition\"])[\"loss\"]\n",
    "        .cummin()\n",
    "    )\n",
    "\n",
    "    # First, get max iteration per (instance, arm_index)\n",
    "    filtered_df[\"max_iteration\"] = filtered_df.groupby(\n",
    "        [\"instance\", \"arm_index\", \"repetition\"]\n",
    "    )[\"iteration\"].transform(\"max\")\n",
    "\n",
    "    # Compute iteration ratio\n",
    "    filtered_df[\"iteration_ratio\"] = (filtered_df[\"iteration\"] + 1) / filtered_df[\n",
    "        \"max_iteration\"\n",
    "    ]\n",
    "    filtered_df[\"avg_eval_time\"] = filtered_df.groupby(\n",
    "        [\"instance\", \"arm_index\", \"iteration\"]\n",
    "    )[\"eval_time\"].transform(\"mean\")\n",
    "\n",
    "    # Compute total eval time per (instance, arm_index)\n",
    "    total_eval_time = (\n",
    "        filtered_df.groupby([\"instance\", \"arm_index\", \"repetition\"])[\n",
    "            \"avg_eval_time\"\n",
    "        ].transform(\"sum\")\n",
    "        # / number_of_trails\n",
    "    )\n",
    "    # print(total_eval_time.min())\n",
    "\n",
    "    # Scale it by iteration ratio\n",
    "    filtered_df[\"cum_eval_time\"] = (total_eval_time) * filtered_df[\"iteration_ratio\"]\n",
    "\n",
    "    filtered_df[\"performance\"] = 1 - filtered_df[\"incumbent_loss\"]\n",
    "\n",
    "    filtered_df = filtered_df.sort_values(\n",
    "        [\"instance\", \"arm_index\", \"repetition\", \"iteration\"]\n",
    "    )\n",
    "    filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "    arm_time_ranges = (\n",
    "        df.groupby(\"arm_name\")[\"cum_eval_time\"].agg([\"min\", \"max\"]).reset_index()\n",
    "    )\n",
    "\n",
    "    # Store interpolated results\n",
    "    all_data = []\n",
    "\n",
    "    for (arm, rep), group in filtered_df.groupby([\"arm_name\", \"repetition\"]):\n",
    "        group_sorted = group.sort_values(\"cum_eval_time\")\n",
    "\n",
    "        arm_min = arm_time_ranges.loc[arm_time_ranges[\"arm_name\"] == arm, \"min\"].values[\n",
    "            0\n",
    "        ]\n",
    "        arm_max = arm_time_ranges.loc[arm_time_ranges[\"arm_name\"] == arm, \"max\"].values[\n",
    "            0\n",
    "        ]\n",
    "\n",
    "        # Define common interpolation time grid for this arm\n",
    "        interp_times = np.linspace(arm_min, arm_max, 100)\n",
    "\n",
    "        # Sort in case cum_eval_time isn't sorted\n",
    "        group_sorted = group.sort_values(\"cum_eval_time\")\n",
    "\n",
    "        # Interpolation function\n",
    "        interp_func = interp1d(\n",
    "            group_sorted[\"cum_eval_time\"],\n",
    "            group_sorted[\"performance\"],\n",
    "            bounds_error=False,\n",
    "            fill_value=\"extrapolate\",\n",
    "        )\n",
    "\n",
    "        # Interpolate to common times\n",
    "        interp_perf = interp_func(interp_times)\n",
    "\n",
    "        # Store results\n",
    "        temp = pd.DataFrame(\n",
    "            {\n",
    "                \"cum_eval_time\": interp_times,\n",
    "                \"performance\": interp_perf,\n",
    "                \"arm_name\": arm,\n",
    "                \"repetition\": rep,\n",
    "            }\n",
    "        )\n",
    "        all_data.append(temp)\n",
    "\n",
    "    # Combine\n",
    "    aligned_df = pd.concat(all_data)\n",
    "\n",
    "    # Now compute mean & CI\n",
    "    summary = (\n",
    "        aligned_df.groupby([\"arm_name\", \"cum_eval_time\"])[\"performance\"]\n",
    "        .agg([\"mean\", \"std\", \"count\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    summary[\"ci95\"] = 1.96 * summary[\"std\"] / np.sqrt(summary[\"count\"])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(3.5, 2.5))\n",
    "    arm_labels = [\"XTab\", \"FLAML\", \"RealMLP\", \"TabForestPFN\", \"TabPFN(v2)\"]\n",
    "    arm_names = [\"xtab\", \"flaml\", \"realmlp\", \"tabforestpfn\", \"tabpfn_v2_phe\"]\n",
    "    for arm, label in zip(arm_names, arm_labels):\n",
    "        arm_data = summary[summary[\"arm_name\"] == arm]\n",
    "        plt.plot(\n",
    "            arm_data[\"cum_eval_time\"], arm_data[\"mean\"], label=label, linewidth=2.5\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            arm_data[\"cum_eval_time\"],\n",
    "            arm_data[\"mean\"] - arm_data[\"ci95\"],\n",
    "            arm_data[\"mean\"] + arm_data[\"ci95\"],\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    # handles, labels = ax.get_legend_handles_labels()\n",
    "    # new_labels = [\"XTab\", \"FLAML\", \"RealMLP\", \"TabForestPFN\", \"TabPFN(v2)\"]\n",
    "    # ax.legend(handles=handles, labels=new_labels, title=\"ML model\", loc=\"lower right\")\n",
    "    # ax.get_legend().remove()\n",
    "\n",
    "    plt.title(\"OpenML-\" + str(instance), fontsize=14)\n",
    "    plt.xlabel(\"Wall-clock time\")\n",
    "    # Set x-axis ticks every hour (3600 seconds)\n",
    "    xticks = np.arange(0, 2 * 3600 + 1, 1 * 3600)\n",
    "    xtick_labels = [f\"{int(t // 3600)}h\" for t in xticks]\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.xticks(xticks, xtick_labels)\n",
    "\n",
    "    plt.xlim(0, 2 * 3600)  # change to your desired range\n",
    "    plt.ylabel(\"Performance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"./figures/\" + dataset_name + \"_\" + str(instance) + \"_performance.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
